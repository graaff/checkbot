<html> <head>
<title>Checkbot information page</title>
</head>

<body>
<h1>Checkbot</h1>

Checkbot is a tool to verify links on a set of html pages. Checkbot
can check a set of documents on a single server, or on a set of
servers (e.g. all servers within a domain). <p>

Checkbot creates a report which summarizes all links which caused some
kind of error or warning. <p>

Please send bug reports, patches, etc. to: <a
href=mailto:checkbot-bugs@twi72.twi.tudelft.nl>checkbot-bugs@twi72.twi.tudelft.nl</a>.

<h2>Getting Checkbot</h2>

The latest Checkbot release is <a href="checkbot.tar.gz">Checkbot
<!-- #include VERSION -->
</a>. <p>

Read the <a href="ChangeLog.html">ChangeLog</a> and <a
href="TODO">TODO</a> files for more information.

Checkbot has the following software requirements:

<ul>
  <li>perl 5.002
  <li><a
      href="http://www.sn.no/libwww-perl/">LWP <b>5.02</b></a>.
      (libwww-perl 5 module) 
  <li>libnet-1.00 (required by LWP)
  <li>Mail::Send (optionally with option -M, available in Mailtools
      archive)
</ul>

All software can be found at <a href="http://www.perl.com/CPAN/">CPAN</a>.

<h2>How does Checkbot work?</h2>

Checkbot collects all links from URL's matching the <b>match
string</b>, and accessible through the <b>start url</b>. It has two
categories of links: internal links (to other URL's matching the
<b>match string</b>), and external links. The external links are filed
for later use, while all internal links are checked.  <p>

After checking all internal links Checkbot will check all external
links found on the pages. It will <em>always</em> use the
<tt>HEAD</tt> method for this. Checkbot does <em>not</em> adhere to
the robots standard (which involves examining <tt>/robots.txt</tt>
from a site first). However, people have brought some good arguments
to my attention, so I will eventually implement this into Checkbot as
well. <p>

After a interval (which gets exponentially longer) Checkbot will write
its current results to a file. This file contains some statistics,
such as number of links processed. It also contains a list of pages
(sorted by server, and per server by page name) which contains links
which generated an HTTP error code, along with that code.<p>

Look at a <a href="sample.html">small sample</a> from Checkbot 1.35 for
my <a href="http://is.twi.tudelft.nl/hci/">HCI Index</a>. I might also
have a more up-to-date, and much larger, <a
href=http://dutifp.twi.tudelft.nl:8000/checkbot-output/checkbot.html>report
for the twi.tudelft.nl domain</a>.

<h2>Usage</h2>

The documentation for Checkbot is contained within it. You can look at
the <a href="checkbot.pl.html">HTML version</a> here.

To check a tree of html pages, just start Checkbot with a starting url
and a match argument. Both are mandatory. For example, to check all
"bar" pages on the "foo.org" server, use:<br>
<pre>
    ./checkbot -u http://foo.org/bar/ -m foo.org/bar
</pre>
  
<h2>Who wrote Checkbot?</h2>

<a href="http://is.twi.tudelft.nl/~graaff/">Hans de Graaff</a> wrote
the last version of Checkbot. Previous versions were written by <a
href="http://www.twi.tudelft.nl/People/D.B.Tischenko.html">Dimitri
Tischenko</a>. Checkbot is originally based on another script by Roy
Fielding.

<hr>
<address>$Revision$</address>

</body> </html>
